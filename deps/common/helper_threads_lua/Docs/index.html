<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html lang="es-pe">
<head>
  <!-- $Id: index.html,v 1.7 2007-08-25 21:42:53 jguerra Exp $-->
  <meta name="description" content="The Helper Threads Toolkit Homepage" />
  <meta name="keywords"
 content="Lua, Library, Multi-Threading, Threads, Support" />
  <title>Helper Threads: Building
blocks for non-blocking libraries.</title>
  <link rel="stylesheet" href="reference.css" type="text/css" />
</head>
<body>
<!-- header +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<div class="header">
<hr />
<p></p>
<center>
<table summary="Lua logo">
  <tbody>
    <tr>
      <td align="center"><a href="http://www.lua.org"><img
 src="logo.gif" alt="Lua" align="middle" border="0" height="128"
 width="128" />
      </a></td>
    </tr>
    <tr>
      <td align="center" valign="top">Helper
Threads: Building blocks for non-blocking libraries.
      </td>
    </tr>
  </tbody>
</table>
<p class="bar">
<a href="#whatis">What is?</a>
&middot;
<a href="#concepts">Concepts</a>
&middot;
<a href="#luaapi">Lua API</a>
&middot;
<a href="#tasks">Included Tasks</a>
&middot;
<a href="#capi">C API</a>
&middot;
<a href="#examples">Examples</a>
</p>
</center>
<hr />
</div>
<!-- whatis +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<h2 id="whatis">What is the Helper Threads Toolkit?</h2>
<p>It's a library to help
	developers build libraries. More specifically, to build non-blocking
	libraries.
</p>
<p>Using Lua as a scripting
	addition for an application works wonderfully; but using it as the main
	development language shows some deficiencies. Most notably, it's almost
	impossible to get a good multithreading environment.
</p>
<p>A coroutine-based dispatcher
	can be a complex project on it's own, especially if it have to manage
	all kinds of potentially blocking libraries. The Helper Threads Toolkit
	makes it easier to do because any library build with it in mind will
	use the same interface to represent non-finished tasks and to signal
	a task's completion. This allows the dispatcher to very simple,
	resuming the apropriate coroutine when a task is done. At the same
	time, it's a framework to make it easy to write those libraries in C,
	because it manages all the thread handling and locking.
</p>
<h2 id="concepts">Concepts:</h2>
<h3>Task</h3>
<p>A task is an action that could
	be time-consuming, therefore it's separated in four steps: Preparation,
	Work, Update(s) and Finishing.
</p>
<p>The first step creates an object (what I call a task object) used to
	identify it at the other three
	steps. The second step, Work, occurs in background; without blocking
	the main Lua execution. The third step, Update, can occur any number of
	times (including zero times), as needed by the Work process. Finally,
	the Finishing step is in fact the only Update done after the Work step
	finishes, it occurs exactly once and the task is disposed.
</p>
<h3>Queue</h3>
<p>These are First-In, First-Out
	(FIFO) queues holding task objects. A task is added at the end of the
	queue with <code>queue:addtask(task)</code>,
	and retrieved at the front with <code>queue:wait([timeout])</code>.
</p>
<p>There are two types of queues:
	input queues, where prepared tasks are added; and output queues, where
	tasks are added by the threads to notify its completion or any
	intermediate event.
</p>
<h3>Thread</h3>
<p>A thread is a separate
	execution context. It's only for C code and it can't touch or access
	the Lua state. This restriction makes the library much simpler, and
	improves performance significatively. Each thread has an input queue
	and an output queue, either one can be shared by several threads.
</p>
<p>During execution, a thread
	waits on it's input queue for a task. When it gets one, it calls it's
	work function. After that function returns, marks the task as "Done"
	and puts it in it's output queue. Finally, returns to waiting on the
	input queue and repeats it all over again.
</p>
<h3>Preparation</h3>
<p>To start a task, it has to get
	some parameters about the work to be performed. Also, it usually have
	to allocate some memory to hold these parameters and any result. All
	this is done in the "Preparation" step, and ends returning the task
	object to the calling Lua code.
</p>
<h3>Work</h3>
<p>This is where all gets done.
	It's the time-consuming step wich we want to avoid blocking the Lua
	code.
</p>
<p>When a thread picks a task from
	its input queue, the task's work function is called. This function does
	all the work according to the parameters collected at the "Preparation"
	step.
</p>
<p>Since this function is called in a separate execution context, it can't
	directly interact with the Lua code; but if needed it can signal an event,
	making the unfinished task object to appear in the output queue. This signaling
	is optional, and can be repeated as many times as needed. There's also the
	option to pause the thread until the task is 'Updated'.
</p>
<h3>Update(s)</h3>
<p>When the task object appears in
	the output queue, the Lua code should do an 'update' on the task. This
	is an opportunity for the C library to interact with the running Lua
	code. These updates should be brief, just to copy some data and/or
	state between the two contexts.
</p>
<p>The task's work function
	initiates these interactions making the task object appear in the
	output queue, optionally blocking itself until the Lua code responds.
	In this case, the thread is resumed as soon as the update is done.
</p>
<h3>Finishing</h3>
<p>This step doesn't have it's own
	API functions; it's just the last update. When the work function
	finishes, the helper library automatically puts the task object in the
	output queue, with a state of "Done"; and after the Lua code calls the
	update function, the task is considered "Finished" and disposed.
</p>
<p>This is where most libraries
	will return data from the work just finished to the calling Lua code.
</p>
<h2 id="luaapi">The Lua API:</h2>
<p>Note that this API doesn't
	provide a function to create a task object. These are created by C
	libraries that use the Helper Thread Toolkit. For example, the <code>nb_file.read(file,
		len)</code> function (part of the
	sample "nb_file" library) creates and returns a task object that
	identifies the read operation and encapsulates the given parameters <code>file</code>
	and <code>len</code>.
</p>
<p>In most cases, the functions described here
	would be called by a Lua dispatcher; that is, some Lua framework that
	manages several Lua threads of execution using coroutines or maybe some
	other methods.
</p>
<h3><code>helper.newqueue ()</code></h3>
<p>Returns a newly created queue
	object.
</p>
<h3><code>helper.newthread (input, output)</code></h3>
<p>Returns a newly created thread
	object. It's spawned and running, so if the input queue has task
	objects in it, they'll be executed ASAP. Either or both queues can be
	shared with other threads.
</p>
<p> If more than one thread have
	the same input queue, you can't predict which one will execute a given
	task. If the input thread is used by only one thread, the tasks will be
	executed sequentially, with no reordering.
</p>
<p>Each task will be added to the
	output queue, where the Lua code can get them using the <code>peek()</code>
	or <code>wait()</code>
	methods. If several threads have the same output queue, a single <code>wait()</code>
	line could get events from all those threads (a single task for each
	call, of course).
</p>
<h3><code>helper.update (task [, ...])</code></h3>
<p>When a task appears at an
	output queue, the Lua code should respond calling this function. The
	task's update handler (in the C library) has access to any extra
	parameters given here, and can return any value(s) to the Lua code.
</p>
<p>If the task is in the "Done"
	state, this update will be the last one for this task; and the task
	will be marked as "Finished" after this call, and eventually disposed.
</p>
<p>If the task is in the "Ready"
	state, it means it has been prepared; but it's not in any queue, so it
	hasn't begun execution by any thread. In this case, the task is
	executed immediately and in a blocking manner. This makes easy for a
	Lua dispatcher to 'wrap' the task preparation functions and provide a
	simple blocking API over the non-blocking one provided by the
	underlying C library.
</p>
<h3><code>helper.state (task)</code></h3>
<p>Returns an string indicating
	the task's state. The possible results are:
</p>
<ul>
	<li>"<code>NULL</code>"
		before the task preparation, shouldn't happen.</li>
	<li>"<code>Ready</code>"
		after preparation, not on a queue.</li>
	<li>"<code>Waiting</code>"
		the task is in a queue, waiting to be picked by a thread.</li>
	<li>"<code>Busy</code>"
		currently being executed by a thread.</li>
	<li>"<code>Paused</code>"
		the thread has paused and put it in the output queue. Maybe has some
		data for you, maybe needs some more data. Call <code>helper.update
			(task [, ...])</code> to interact
		with it and unpause the thread.</li>
	<li>"<code>Done</code>",
		The task's work is done, call <code>helper.update
			(task [, ...])</code> to get any
		result(s).</li>
	<li>"<code>Finished</code>",
		It has fulfilled it's purpose in life and will be soon disposed.</li>
</ul>
<h3><code>queue:addtask (task)</code></h3>
<p>Use this function to add tasks
	to input queues. The task should be in the "Ready" state, or it will be
	rejected. If the queue is currently empty and has a thread waiting on
	it, the task would be immediatly picked and executed.
</p>
<h3><code>queue:remove (task)</code></h3>
<p>Removes a task from the queue.
	If it was in the "Waiting" state, it's returned to the "Ready" state.
	Returns the given task if successful, or nil if not (maybe it wasn't in
	this queue anymore).
</p>
<h3><code>queue:peek ()</code></h3>
<p>Returns the front task of a
	queue, or nil if the queue was empty. Doesn't block nor modify the
	queue in any way.
</p>
<h3><code>queue:wait ([timeout])</code></h3>
<p>Removes and returns the front
	task from the queue. If the queue is empty, it waits at most <code>timeout</code>
	seconds before returning nil. If no <code>timeout</code>
	is given, blocks indefinitely until a task appears in the queue.
</p>
<h2 id="tasks">Included Tasks</h2>
<p>The Helper library includes a
	few tasks that can be useful for dispatchers:
</p>
<h3><code>helper.null ()</code></h3>
<p>The simplest possible task. When a thread picks a null task from its
	input queue, it will immediately put it in the output queue without any
	processing. Even if it doesn't do anything, it has to be finished with
	a call to <code>helper.update (task)</code>.
</p>
<h3><code>helper.waiter (queue [, timeout])</code></h3>
<p>A background version of <code>queue:wait ([timeout])</code>, this task will
	wait up to <code>timeout</code> seconds for a task to appear in
	<code>queue</code>. The task will be returned by the <code>helper.update()</code>
	call. Its purpose is to allow a Lua thread (running under a
	coroutine-based dispatcher) to manage its own tasks, queues and threads.
</p>
<p>Note that the timeout parameter is taken with respect to the task creation
	time, not with respect to the time the task was picked by the thread.
</p>
<h2 id="capi">The C API</h2>
<p>This API is defined in the <code>helper.c</code> file, for use by C
	programmers that use the Helper Threads Toolkit to create non-blocking
	libraries. For each 'task-able' operation, the library writer has to
	provide three C callback functions and register them as the task
	operations.
</p>
<h3><code>int (*prepare) (lua_State *L, void **udata)</code></h3>
<p>This user-defined function is
	called in the main thread. It should get any needed parameters from the
	Lua State, and set <code>*udata</code>
	to a pointer holding any userdata associated with the task.
</p>
<h3><code>int (*work) (void *udata)</code></h3>
<p>This callback is the one doing
	all the work. It gets called by the helper thread and shouldn't touch
	or access in any way the Lua state. The <code>*udata</code>
	provided is the same one set by <code>prepare()</code>
	for this task, it should point to a private structure holding any
	parameter needed.
</p>
<p>One-shot tasks only need to do
	any work in this function, probably blocking on I/O, and store any
	results in the userdata structure. When this function finishes, the
	helper threads library will set the task's state to "Done" and put it
	in the output queue, maybe waking up a waiting Lua code.
</p>
<p>Long-running tasks might want
	to signal events to the Lua code, maybe to return some intermediate
	results or maybe to request some more data to work. Use the <code>signal_task()</code>
	function for that.
</p>
<h3><code>int (*update) (lua_State *L, void *udata)</code></h3>
<p>This callback is executed each
	time the Lua code calls the <code>helper.update(task)</code>
	function. It's has access both to the Lua state (to get any extra
	parameter and/or return any result) and to the task's userdata.
</p>
<p>After this function returns,
	the task state will be updated. If the task was in the "Paused" state,
	it'll be reset to the "Busy" state and any waiting thread will be
	resumed. If it was in the "Done" state (because the <code>work()</code>
	callback has already returned), it'll be set to the "Finished" state
	and disposed soon.
</p>
<pre><h3><code>typedef struct task_ops {
	int (*prepare) (lua_State *L, void **udata);
	int (*work) (void *udata);
	int (*update) (lua_State *L, void *udata);
} task_ops;</code></h3></pre>
<p>This struct holds the three
	callbacks for a task. Used in the <code>add_helperfunc()</code>
	function and <code>task_reg</code>
	structure.
</p>
<h3><code>void add_helperfunc (lua_State *L, const task_ops *ops)</code></h3>
<p>Used to create a task type
	associated with the callbacks in the <code>ops</code>
	parameter. Pushes in the Lua stack the Lua function that creates,
	prepares and returns the task.
</p>
<pre><h3><code>typedef struct task_reg {
	const char *name;
	const task_ops *ops;
} task_reg;<br /></code></h3></pre>
<p>This struct associates a name with a <code>task_ops</code>
	structure. Used in the <code>tasklib()</code> function.
</p>
<h3><code>void tasklib (lua_State *L, const char *libname, const task_reg *l)</code></h3>
<p>Analogous to the <code>luaL_openlib()</code> function. <code>libname</code>
	is a C string with the name to be given to the library. If <code>libname</code>
	is <code>NULL</code>, it uses the table that should be at the top of
	the Lua stack. <code>l</code>
	points to an array of <code>task_reg</code> structures (finished by a
	<code>{NULL, NULL}</code> record) specifying the
	names and callbacks of any 'task-able' operations. At return, the
	library's table is left on the Lua stack.
</p>
<h3><code>void signal_task (int pause)</code></h3>
<p>This utility function can be called by the <code>work</code>
	callback to signal the Lua code. The current task will appear in the
	output queue, where it would eventually be picked by the <code>queue:wait()</code>
	function.
</p>
<p>If <code>pause</code> is non-zero, the task is put in the "Paused" state
	and the thread blocks, waiting for the Lua code to call the
	<code>helper.update(task)</code> function. This is useful if the
	operation can't continue without some interaction with the Lua code.
</p>

<h2 id="examples">Examples</h2>

<h3>timer.c</h3>
<p>This code implements two different timers: one-shot and repeated-ticks.
</p>
<ul>
	<li><h4><code>timer.timer (t)</code></h4>
	<p>Returns a task that will pause for <code>t</code> seconds. This time is counted
		from the moment the background thread picks it from its input queue.
		The <code>helper.update()</code> call returns nothing and finishes the task.
	</p></li>
	<li><h4><code>timer.ticks (t)</code></h4>
	<p>Returns a task that will be signalled every <code>t</code> seconds. The
		<code>helper.update()</code> call takes a second parameter (besides the
		signalled task). If it's a non-negative number, it changes the tick period
		(after the current period). Any negative number finishes the ticker, the
		task will be signalled a last time, and has to be diposed by calling
		<code>helper.update()</code> again.
	</p></li>
</ul>

<h3>nb_file.c</h3>
<p>A small file I/O library. Uses the same file handles as the standard <code>io</code>
	package. Since the real I/O would occur at some time after the task creation, it's
	important not to manipulate the file using the same handler until the task is done.
	It's OK to use other handlers, even if they point to the same file (at least on
	POSIX systems).
</p>
<ul>
	<li><h4><code>nb_file.read (file, size)</code></h4>
	<p>Reads from <code>file</code>, <code>size</code> can be:</p>
	<ul>
		<li><em><strong>number</strong></em>: reads up to that many characters (could be less at the end of file).</li>
		<li><strong>"*l"</strong>: reads a line, without the end of line character.</li>
		<li><strong>"*a"</strong>: reads the whole file.</li>
	</ul>
	<p>The <code>helper.update()</code> call will return read data as a string,
		<code><strong>nil</strong></code> at end of file, or <code><strong>nil</strong></code>
		and an error message on failure.
	</p></li>
	<li><h4><code>nb_file.write (file, data)</code></h4>
	<p>Writes <code>data</code> on <code>file</code>. The <code>helper.update()</code>
		call will return <code><strong>true</strong></code> on success, or
		<code><strong>nil</strong></code> and an error message otherwise.
	</p></li>
</ul>

<h3>nb_tcp.c</h3>
<p>A very minimal TCP I/O library. Only those functions that would potentially block
	(<code>newclient()</code>, <code>accept()</code>, <code>read()</code>,
	<code>write()</code>) return a task; but others (<code>newserver()</code>,
	<code>close()</code>) don't need it and work as usual. There are two different
	objects: Server Port objects and TCP Stream objects. The first are used only to
	open a port and accept connections, while the second type represent opened
	connections, created either as clients (with <code>newclient()</code>), or
	as server, after accepting a connection.
</p>
<ul>
	<li><h4><code>nb_tcp.newclient (remaddr, remport [, localport])</code></h4>
		<p>Creates a new TCP stream and connects it to the server at host address
			<code>remaddr</code>, port number <code>remport</code>, optionally
			specifying a local port with <code>localport</code>. The
			<code>helper.update()</code> call will return the new tcpstream object,
			or <code><strong>nil</strong></code> and an error message on failure.
		</p>
	</li>
	<li><h4><code>nb_tcp.newserver (tcpport)</code></h4>
		<p>Creates a Server Port object, accepting TCP connections on the given
			port.
		</p>
	</li>
	<li><h4><code>server:accept ()</code></h4>
		<p>Returns a task that will wait until another host opens a connection on
			the server port. The <code>helper.update()</code> call returns a
			TCP Stream with the new connection, or <code><strong>nil</strong></code>
			and an error message on failure.
		</p>
	</li>
	<li><h4><code>stream:write (data)</code></h4>
		<p>Returns a task that will write the data on the stream. The task won't
			be done until all the data has been written. The <code>helper.update()</code>
			call returns <code><strong>true</strong></code> on success or
			<code><strong>nil</strong></code> and an error message on failure.
		</p>
	</li>
	<li><h4><code>stream:read (mode)</code></h4>
		<p>Returns a task that reads data from the stream. The task won't be done
			until enough data has been read to satisfy the <code>mode</code>.
		</p>
		<ul>
			<li><em><strong>number</strong></em>: reads that many characters.</li>
			<li><strong>"*l"</strong>: reads a line, without the end of line character.</li>
		</ul>
		<p>The <code>helper.update()</code> call returns a string containing the data,
			or <code><strong>nil</strong></code> and an error message on failure.
		</p>
	</li>
	<li><h4><code>server:close()<br />stream:close()</code></h4>
		<p>Close the stream or server port. The object is invalid after a call to
			this function. If this function is not called, the garbage collector
			calls it just before disposing it; but it's better to do it as soon as
			appropriate, to release unneeded resources.
		</p>
	</li>
</ul>

<h3>sched.lua</h3>
<p>A simple coroutine-based scheduler. Programs written using this scheduler shouldn't have
to call any function from the <code>helper</code> package; just wrap any task-producing
function with <code>sched.yield()</code> to block the current Lua thread.
</p>
<ul>
	<li><h4><code>sched.add_helpers (name, n_helpers)</code></h4>
		<p>Adds <code>n_helpers</code> helper threads waiting on the input queue identified
			by <code>name</code>, creating it too if needed.
		</p></li>
	<li><h4><code>sched.add_thread (f [, name])</code></h4>
		<p>Add the function <code>f</code> as a Lua thread, encapsulated in a coroutine. If
			<code>name</code> is given, any task created by this thread is added to the named
			queue (and executed by the set of threads associated with it); if not, the Lua
			thread is given it's own input queue and helper thread for exclusive use.
		</p>
		<p>To run a task, return it to the scheduler with <code>coroutine.yield()</code>.
			The scheduler will put it in the appropriate input queue, and when it appears
			in the output queue (either because it's done or because it has been signalled
			by the helper thread), returns it to the Lua thread in the <code>coroutine.yield()</code>
			result; ready to be processed with <code>helper.update()</code>. Look
			<code>sched.yield()</code> for an easier way to do this.
		</p></li>
	<li><h4><code>sched.run ()</code></h4>
		<p>Main loop; runs the registered Lua threads, dispatching tasks to each one
			until all of them are finished.
		</p></li>
	<li><h4><code>sched.yield (task, ...)</code></h4>
		<p>Equivalent to <code>helper.update (coroutine.yield (task), ...)</code>, 
			should be used from a Lua thread.  It's easy to write blocking-style code just
			wrapping any task-producing function with this. Note that the extra parameters
			are fed to the <code>helper.update()</code> call after the task appears on
			the output queue, in most cases that would be when the task is done, and
			usually don't use any parameter, just return the results.
		</p></li>
	<li><h4><code>sched.par_foreach (in_t, f_a, f_b, n)</code></h4>
		<p>Processes the table <code>in_t</code> using <code>n</code> helper threads. Each
			item in the table is passed to <code>f_a</code>, which is a function that
			returns a task. When each task is done, it's passed to <code>f_b</code>.
			The <code>par_foreach ()</code> function returns a table with the same
			keys as <code>in_t</code>, but with the results of <code>f_b()</code> as
			values.
		</p>
		<p> This function doesn't really belong with the scheduler, it's just a simple
			example of how to use helper threads for a discrete operation.
		</p></li>
</ul>

<h3>Example 1:</h3>
<p>For example, this is a scheduler-friendly file copying function that uses
	<code>nb_file</code> I/O functions:
</p>
<pre style="margin : 0 0 0 50px;"><code>local BLKSIZE = 10000
		
local function copy (infname, outfname)
	local infile = assert (io.open (infname, "r"))
	local outfile = assert (io.open (outfname, "w"))
		
	while true do
		local blk = sched.yield (nb_file.read (infile, BLKSIZE)))
		if blk == nil then break end
		
		sched.yield (nb_file.write (outfile, blk)))
	end
		
	outfile:close ()
	infile:close ()
end
</code></pre>
<p>Note how <code>sched.yield()</code> is used to hide all the managing of the task
	objects, so that the code looks like 'normal' blocking style code. This
	<code>copy()</code> function can be used like this to do two copies in parallell:
</p>
<pre style="margin : 0 0 0 50px;"><code>sched.add_thread (function ()
	copy ("srcfile", "dstfile-A")
end)
sched.add_thread (function ()
	copy ("srcfile", "dstfile-B")
end)

sched.run ()
</code></pre>

<h3>Example 2:</h3>
<p>A simple line-oriented "echo server"</p>
<pre style="margin : 0 0 0 50px;"><code>require "helper"
require "sched"
require "nb_tcp"

function do_listen ()
	-- listens on a port and spawns a thread for each connection.
	local srv = assert (nb_tcp.newserver (3000))
	while true do
		local conn = assert (sched.yield (srv:accept ()))
		sched.add_thread (function ()
			handle_client (conn)
		end, "server_helpers")
	end
end

function handle_client (conn)
	-- reads each line and responds with an echo.
	local ln
	repeat
		ln = assert (sched.yield (conn:read ("*l")))
		assert (sched.yield (conn:write ("=>"..ln.."\n")))
		print (ln)
	until ln == "quit"
	conn:close()
end

sched.add_helpers ("server_helpers", 10)
sched.add_thread (do_listen)
sched.run()
</code></pre>

<p>Note that each connection gets its own Lua thread, but uses the same pool of helpers.
</p>

<!-- download +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<!-- footer +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ -->
<div class="footer">
<hr />
<center>
	<p class="bar">
		<a href="#whatis">What is?</a>
		&middot;
		<a href="#concepts">Concepts</a>
		&middot;
		<a href="#luaapi">Lua API</a>
		&middot;
		<a href="#tasks">Included Tasks</a>
		&middot;
		<a href="#capi">C API</a>
		&middot;
		<a href="#examples">Examples</a>
	</p>
</center>
</div>
<p align="right" style="font : x-small serif;">Copyright &copy; 2006 Javier Guerra G. All rights reserved.</p>
</body>
</html>
